{
  "name": "Antigravity Coordinator",
  "description": "Self-optimizing multi-agent coordinator — packages existing infrastructure (coordinator, DQ scoring, ACE, pattern orchestrator) into a standalone pip-installable Python product with research-driven self-improvement loops.",
  "branchName": "ralph/antigravity-coordinator",
  "userStories": [
    {
      "id": "US-001",
      "title": "Python Package Scaffolding",
      "description": "As a developer, I want to install antigravity-coordinator via pip so that I can use the coordinator as a standalone tool.",
      "acceptanceCriteria": [
        "Create ~/projects/products/antigravity-coordinator/ with pyproject.toml using hatchling build system",
        "Package name: antigravity-coordinator, import name: coordinator",
        "Source layout: src/coordinator/ with __init__.py containing __version__ = '0.1.0'",
        "Entry points: coord = 'coordinator.cli:main' and coord-api = 'coordinator.api.server:main'",
        "Dependencies: click, fastapi, uvicorn, sqlite-utils, rich",
        "Dev dependencies in [project.optional-dependencies]: pytest, mypy, ruff, httpx",
        "Create minimal src/coordinator/cli.py with Click group and --version option",
        "Create minimal src/coordinator/api/__init__.py and src/coordinator/api/server.py stubs",
        "uv pip install -e '.[dev]' works without errors",
        "coord --version prints 0.1.0",
        "pytest tests/ -x --tb=short passes",
        "mypy src/ --strict passes",
        "ruff check src/ passes",
        "ruff format --check src/ passes"
      ],
      "priority": 1,
      "passes": true,
      "notes": "Foundation story — every other story depends on this. Follow UCW package pattern from ~/projects/products/ucw/.",
      "dependsOn": [],
      "completionNotes": "Completed by agent"
    },
    {
      "id": "US-011",
      "title": "SQLite Storage Layer",
      "description": "As a developer, I want all coordinator data in SQLite (WAL mode) so that reads and writes are concurrent, reliable, and queryable.",
      "acceptanceCriteria": [
        "Create src/coordinator/storage/__init__.py and src/coordinator/storage/database.py",
        "Database class with connection pooling and context manager support",
        "Tables: sessions, agents, outcomes, baselines, patterns, dq_scores — created via ensure_tables() method",
        "WAL mode enabled by default (PRAGMA journal_mode=WAL on connect)",
        "Version tracking table for schema migrations",
        "All INSERT statements use ON CONFLICT upserts, never INSERT OR REPLACE",
        "coord init creates ~/.coordinator/ directory structure and initializes database",
        "Add init command to cli.py that calls database.ensure_tables()",
        "Unit tests for CRUD operations on each table",
        "pytest tests/ -x --tb=short passes",
        "mypy src/ --strict passes",
        "ruff check src/ passes",
        "ruff format --check src/ passes"
      ],
      "priority": 2,
      "passes": true,
      "notes": "Storage must come before engine — engine writes to DB. Use ON CONFLICT pattern (lesson from CCC dashboard fix where INSERT OR REPLACE zeroed columns).",
      "dependsOn": [
        "US-001"
      ],
      "completionNotes": "Completed by agent"
    },
    {
      "id": "US-002",
      "title": "Migrate Core Orchestration Engine",
      "description": "As a developer, I want the coordinator's core orchestration logic packaged in the library so that agent spawning, registry, and conflict resolution work standalone.",
      "acceptanceCriteria": [
        "Port ~/.claude/coordinator/orchestrator.py → src/coordinator/engine/orchestrator.py",
        "Port ~/.claude/coordinator/registry.py → src/coordinator/engine/registry.py",
        "Port ~/.claude/coordinator/distribution.py → src/coordinator/engine/distribution.py",
        "Port ~/.claude/coordinator/conflict.py → src/coordinator/engine/conflict.py",
        "Port ~/.claude/coordinator/executor.py → src/coordinator/engine/executor.py",
        "Create src/coordinator/engine/__init__.py exporting key classes",
        "Remove all hardcoded paths — use configurable data_dir defaulting to ~/.coordinator/",
        "Use storage.database for persistence instead of JSON files",
        "All imports resolve correctly from new package structure",
        "Unit tests for orchestrator task decomposition, registry CRUD, conflict detection",
        "pytest tests/ -x --tb=short passes",
        "mypy src/ --strict passes",
        "ruff check src/ passes",
        "ruff format --check src/ passes"
      ],
      "priority": 3,
      "passes": true,
      "notes": "Read existing source files at ~/.claude/coordinator/ before porting. Adapt to use SQLite storage from US-011 instead of JSON files.",
      "dependsOn": [
        "US-001",
        "US-011"
      ],
      "completionNotes": "All 5 engine files (orchestrator, registry, distribution, conflict, executor) ported with configurable data_dir. __init__.py exports 18 classes. Database used for state, JSONL for audit logs. 150 tests passing."
    },
    {
      "id": "US-003",
      "title": "Migrate Coordination Strategies",
      "description": "As a user, I want to run coord research|implement|review|full|team so that I can coordinate agents with proven strategies.",
      "acceptanceCriteria": [
        "Port parallel_research.py → src/coordinator/strategies/research.py",
        "Port parallel_implement.py → src/coordinator/strategies/implement.py",
        "Port review_build.py → src/coordinator/strategies/review.py",
        "Port full_orchestration.py → src/coordinator/strategies/full.py",
        "Create src/coordinator/strategies/team.py for Opus 4.6 agent teams",
        "Create src/coordinator/strategies/__init__.py with STRATEGIES registry dict",
        "Base strategy class with execute(task, options) interface",
        "Wire CLI commands: coord research, coord implement, coord review, coord full, coord team",
        "coord status shows active agents from registry with Rich table formatting",
        "Unit tests for strategy registry lookup and base class interface",
        "pytest tests/ -x --tb=short passes",
        "mypy src/ --strict passes",
        "ruff check src/ passes",
        "ruff format --check src/ passes"
      ],
      "priority": 4,
      "passes": true,
      "notes": "Read existing strategy files at ~/.claude/coordinator/strategies/ before porting. Each strategy should use engine.executor for agent spawning.",
      "dependsOn": [
        "US-002"
      ],
      "completionNotes": "5 strategies (research, implement, review, full, team) with STRATEGIES registry. BaseStrategy ABC with execute(). All CLI commands wired. Status command with Rich tables."
    },
    {
      "id": "US-004",
      "title": "Port DQ Scoring Engine to Python",
      "description": "As a developer, I want the DQ scoring engine in Python (not Node.js) so that the entire package is single-language with no external runtime dependencies.",
      "acceptanceCriteria": [
        "Create src/coordinator/scoring/__init__.py, dq_scorer.py, and complexity_analyzer.py",
        "DQ formula: score = validity * 0.35 + specificity * 0.25 + correctness * 0.40",
        "Complexity analysis: token counting + 7 signal categories (architecture, multiFile, code, analysis, creation, debug, simple)",
        "Historical learning from SQLite dq_scores table (replaces JSONL reads)",
        "Opus 4.6 thinking tier selection: low [0.60-0.72], medium [0.72-0.85], high [0.85-0.95], max [0.95-1.0]",
        "Baselines loaded from ~/.coordinator/baselines.json with research lineage tracking",
        "Public API: coordinator.scoring.score('query') returns dict with model, complexity, dq, components",
        "Copy baselines.json from ~/.claude/kernel/baselines.json as default baseline",
        "Unit tests verify scoring output for 5 known queries matches expected model selections",
        "pytest tests/ -x --tb=short passes",
        "mypy src/ --strict passes",
        "ruff check src/ passes",
        "ruff format --check src/ passes"
      ],
      "priority": 5,
      "passes": true,
      "notes": "Read ~/.claude/kernel/dq-scorer.js and ~/.claude/kernel/complexity-analyzer.js before porting. Use routing-test-suite.py test cases as ground truth for validation.",
      "dependsOn": [
        "US-001",
        "US-011"
      ],
      "completionNotes": "DQ formula (V*0.35+S*0.25+C*0.40), 7 signal categories, Opus 4.6 thinking tiers (low/medium/high/max), public API coordinator.scoring.score(), baselines v1.1.0 with research lineage."
    },
    {
      "id": "US-012",
      "title": "Spectral Guardrails — Safety Constraints",
      "description": "As a user, I want safety constraints on agent behavior so that agents can't exceed cost budgets, time limits, or scope boundaries.",
      "acceptanceCriteria": [
        "Create src/coordinator/safety/__init__.py and guardrails.py",
        "Guardrails class with configurable constraints: max_cost, max_duration, allowed_globs, heartbeat_timeout",
        "Cost budget: optional max spend per coordination session (default: None = no limit)",
        "Time limit: configurable max duration per agent (default: 300s)",
        "Scope boundary: agents can only modify files matching specified glob patterns (default: any)",
        "Heartbeat monitoring: detect and kill agents that stop responding (60s timeout)",
        "Stale lock cleanup: automatically release file locks held >5 minutes",
        "coord config set and coord config get CLI commands for guardrail settings",
        "Guardrails are checked continuously via a monitor loop, not just at start",
        "Unit tests for each guardrail trigger: cost exceeded, time exceeded, scope violation, heartbeat timeout",
        "pytest tests/ -x --tb=short passes",
        "mypy src/ --strict passes",
        "ruff check src/ passes",
        "ruff format --check src/ passes"
      ],
      "priority": 6,
      "passes": true,
      "notes": "These safety constraints protect against runaway agents. Integrate with engine.executor so every spawned agent is monitored.",
      "dependsOn": [
        "US-002"
      ],
      "completionNotes": "Guardrails class with max_cost, max_duration, allowed_globs, heartbeat_timeout. check_all() consolidates checks. PurePosixPath.full_match() for ** glob support. Stale lock cleanup via ConflictManager."
    },
    {
      "id": "US-005",
      "title": "Entropy-Guided Compute Allocation (EGSS)",
      "description": "As a user, I want the coordinator to spend more compute where uncertainty is highest so that hard subtasks get proportionally more resources.",
      "acceptanceCriteria": [
        "Create src/coordinator/optimization/__init__.py and entropy_allocator.py",
        "Calculate per-subtask entropy from: DQ score variance, historical failure rate, complexity score",
        "EntropyAllocator class with allocate(tasks, budget) method",
        "High-entropy tasks: more agents, more capable models, longer timeouts",
        "Low-entropy tasks: cheaper models, shorter timeouts, fewer agents",
        "Budget is expressed as total compute units (model_cost * expected_tokens)",
        "Integration point: strategies call allocator.allocate() before spawning agents",
        "Unit tests: 5 tasks with known entropies verify proportional budget allocation",
        "pytest tests/ -x --tb=short passes",
        "mypy src/ --strict passes",
        "ruff check src/ passes",
        "ruff format --check src/ passes"
      ],
      "priority": 7,
      "passes": true,
      "notes": "Based on EGSS paper (Entropy-Guided Search Scaling). The key insight: don't allocate uniformly — spend more where the model is least certain.",
      "dependsOn": [
        "US-004"
      ],
      "completionNotes": "EntropyAllocator with allocate(tasks, budget). Entropy = 0.4*complexity + 0.3*failure_rate + 0.3*dq_variance. Budget-aware with model downgrade fallbacks."
    },
    {
      "id": "US-006",
      "title": "Dynamic Agent Topology Selection (Agyn-inspired)",
      "description": "As a user, I want the coordinator to automatically choose the best agent topology based on task characteristics.",
      "acceptanceCriteria": [
        "Create src/coordinator/optimization/topology_selector.py",
        "TopologySelector class with select(task_graph) method",
        "Four topologies: parallel (independent), sequential (chain), hybrid (partial deps), hierarchical (supervisor+workers)",
        "Selection logic: all independent → parallel; linear chain → sequential; partial deps → hybrid; complexity > 0.9 → hierarchical with Opus supervisor",
        "TaskGraph dataclass: list of subtasks with dependency edges",
        "Returns TopologyResult with topology type, agent assignments, and execution order",
        "Integration with strategies: strategy consults topology_selector before configuring agents",
        "Unit tests for each of the 4 topology selection paths with appropriate task graphs",
        "pytest tests/ -x --tb=short passes",
        "mypy src/ --strict passes",
        "ruff check src/ passes",
        "ruff format --check src/ passes"
      ],
      "priority": 8,
      "passes": true,
      "notes": "Inspired by Agyn paper (72.2% SWE-bench via dynamic topology selection). This is what makes the coordinator 'self-optimizing' at the structural level.",
      "dependsOn": [
        "US-002",
        "US-004"
      ],
      "completionNotes": "TopologySelector with select(task_graph). 4 topologies: parallel, sequential, hybrid, hierarchical. Hierarchical checked before linear chain. Connectivity validation in _is_linear_chain."
    },
    {
      "id": "US-009",
      "title": "Pattern Detection and Strategy Suggestion",
      "description": "As a user, I want the coordinator to detect what kind of work I'm doing and suggest the optimal strategy automatically.",
      "acceptanceCriteria": [
        "Create src/coordinator/optimization/pattern_detector.py",
        "PatternDetector class with detect(task_description) method",
        "8 patterns: debugging, research, architecture, refactoring, implementation, testing, documentation, optimization",
        "Keyword-based detection with weighted scoring per pattern",
        "Pattern → strategy mapping: debugging→review, research→research, architecture→full, refactoring→implement, implementation→implement, testing→review, documentation→research, optimization→full",
        "Confidence scoring: >0.8 auto-selects, 0.5-0.8 suggests with Rich prompt, <0.5 asks user",
        "coord auto 'task' CLI command that auto-selects strategy",
        "Log pattern detections to SQLite patterns table for trend analysis",
        "Unit tests: 8 test queries (one per pattern) correctly detected",
        "pytest tests/ -x --tb=short passes",
        "mypy src/ --strict passes",
        "ruff check src/ passes",
        "ruff format --check src/ passes"
      ],
      "priority": 9,
      "passes": true,
      "notes": "Port logic from ~/.claude/scripts/detect-session-pattern.py. The auto command is the primary UX innovation — users shouldn't need to pick strategies manually.",
      "dependsOn": [
        "US-003",
        "US-004"
      ],
      "completionNotes": "PatternDetector with 8 patterns, keyword-based scoring, confidence thresholds (>0.8 auto, 0.5-0.8 suggest). coord auto command wired. Pattern logging to SQLite."
    },
    {
      "id": "US-007",
      "title": "ACE Post-Session Analysis Integration",
      "description": "As a user, I want every coordination session automatically analyzed by ACE so that the coordinator learns from successes and failures.",
      "acceptanceCriteria": [
        "Create src/coordinator/feedback/__init__.py and ace_analyzer.py",
        "Port 6 ACE analysis functions: outcome_detector, quality_scorer, complexity_analyzer, model_efficiency, productivity_analyzer, routing_quality",
        "Each function takes session data dict and returns AnalysisResult with summary, dq_score, confidence",
        "Consensus synthesis: weighted DQ voting across all 6 functions to produce final outcome",
        "Store session outcomes in SQLite outcomes table via storage.database",
        "Auto-trigger: strategies call ace_analyzer.analyze(session) on completion",
        "coord history CLI command shows last 10 outcomes with Rich table (date, task, outcome, quality, dq)",
        "Unit tests for consensus calculation with known synthetic agent outputs",
        "pytest tests/ -x --tb=short passes",
        "mypy src/ --strict passes",
        "ruff check src/ passes",
        "ruff format --check src/ passes"
      ],
      "priority": 10,
      "passes": true,
      "notes": "Port logic from ~/.claude/scripts/observatory/post-session-analyzer.py and agents/. Simplify to pure functions — no subprocess spawning for analysis.",
      "dependsOn": [
        "US-011",
        "US-004"
      ],
      "completionNotes": "6 ACE analysis functions as pure functions. DQ-weighted consensus synthesis with outcome_detector 2x weight. coord history with Rich table. Auto-trigger on strategy completion."
    },
    {
      "id": "US-008",
      "title": "Self-Optimization Feedback Loop",
      "description": "As a user, I want the coordinator to automatically improve its baselines when it has enough evidence so that routing accuracy improves over time.",
      "acceptanceCriteria": [
        "Create src/coordinator/feedback/optimizer.py",
        "Optimizer class with propose() and apply() methods",
        "After 50+ sessions in DB, calculate optimal complexity thresholds from outcome data",
        "Propose baseline updates only when confidence > 75% and observation window > 30 days",
        "Auto-apply updates that improve accuracy by >5% on holdout set (random 20% of sessions)",
        "Safety: rollback if any metric drops >10% after update applied",
        "Research lineage: each update records timestamp, evidence count, confidence, and parameter changes",
        "coord optimize --dry-run shows proposed changes as Rich table without applying",
        "coord optimize --apply applies validated improvements and logs lineage",
        "Unit tests for threshold calculation from 100 synthetic session outcomes",
        "pytest tests/ -x --tb=short passes",
        "mypy src/ --strict passes",
        "ruff check src/ passes",
        "ruff format --check src/ passes"
      ],
      "priority": 11,
      "passes": true,
      "notes": "This is the crown jewel — the self-optimization loop. Combine ACE outcomes + DQ scores + pattern trends to propose better baselines. Conservative by design (30 day window, 75% confidence, auto-rollback).",
      "dependsOn": [
        "US-007"
      ],
      "completionNotes": "Optimizer with propose()/apply()/rollback(). 50+ session threshold, 75% confidence gate, auto-rollback on >10% metric drop. coord optimize --dry-run/--apply commands."
    },
    {
      "id": "US-010",
      "title": "FastAPI Server for Programmatic Access",
      "description": "As an application developer, I want to access the coordinator via HTTP API so that I can integrate it into OS-App and other frontends.",
      "acceptanceCriteria": [
        "Create src/coordinator/api/server.py with FastAPI app",
        "POST /api/coordinate — start a coordination session (accepts strategy, task, options as JSON body)",
        "GET /api/status — get active agents and their state from registry",
        "GET /api/history — get session outcomes with DQ scores (paginated, default last 20)",
        "GET /api/health — health check returning status, version, uptime",
        "GET /api/metrics — routing accuracy, cost efficiency, DQ trends from last 30 days",
        "SSE endpoint GET /api/stream for real-time agent progress updates",
        "coord-api --port 3848 starts the server (click option with default 3848)",
        "Integration test: POST coordinate request, GET status, verify response schemas",
        "pytest tests/ -x --tb=short passes",
        "mypy src/ --strict passes",
        "ruff check src/ passes",
        "ruff format --check src/ passes"
      ],
      "priority": 12,
      "passes": true,
      "notes": "Follow CCC API server pattern (SSE streaming, /api/ prefix). Use httpx.AsyncClient in tests.",
      "dependsOn": [
        "US-002",
        "US-003",
        "US-011"
      ],
      "completionNotes": "FastAPI app with 6 endpoints: POST /api/coordinate, GET /api/status, /api/history, /api/health, /api/metrics, SSE /api/stream. coord-api entry point on port 3848."
    }
  ],
  "metadata": {
    "updatedAt": "2026-02-13T05:23:47.799Z"
  }
}